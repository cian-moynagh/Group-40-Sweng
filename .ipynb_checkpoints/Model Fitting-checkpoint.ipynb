{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pandas-datareader\n",
    "#! pip install pmdarima\n",
    "#! pip install plotly\n",
    "import numpy as np\n",
    "from pandas_datareader import DataReader # pip install pandas-datareader\n",
    "from pandas_datareader import data\n",
    "from datetime import datetime\n",
    "from pmdarima.arima import *\n",
    "from pmdarima import preprocessing\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "\n",
    "from statsmodels import api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import pandas as pd\n",
    "import pmdarima as pm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    " \n",
    "start = pd.to_datetime('2010-01-01') # in YYYY-MM-DD format\n",
    "end = pd.to_datetime('2018-01-01')\n",
    "ts = data.DataReader('NDAQ', 'yahoo', start , end) # here 'yahoo' is the API to yahoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all normalisation functions before modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043066305774378665\n",
      "0.0391631256848633\n"
     ]
    }
   ],
   "source": [
    "#transformed data\n",
    "boxCoxData, boxCox_lambda = stats.boxcox(ts.Close)\n",
    "boxCoxSkew = skew(boxCoxData)\n",
    "\n",
    "#we want to compare their absolute skewness \n",
    "if(boxCoxSkew < 0):\n",
    "    boxCoxSkew = boxCoxSkew * -1\n",
    "\n",
    "johnsonData, johnson_lambda = stats.yeojohnson(ts.Close)\n",
    "johnsonSkew = skew(johnsonData)\n",
    "\n",
    "if(johnsonSkew < 0):\n",
    "    johnsonSkew = johnsonSkew * -1\n",
    "\n",
    "#to show which is less skewed \n",
    "print(johnsonSkew)\n",
    "print(boxCoxSkew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0391631256848633"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if(johnsonSkew < boxCoxSkew):\n",
    "    normalised_Data = johnsonData\n",
    "    fitted_lambda = johnson_lambda\n",
    "    \n",
    "#being == doesn't really matter same either way\n",
    "elif(boxCoxSkew <= johnsonSkew):\n",
    "    normalised_Data = boxCoxData\n",
    "    fitted_lambda = boxCox_lambda\n",
    "\n",
    "\n",
    "skew(normalised_Data)\n",
    "#print(fitted_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = px.line(ts.Close, x=[ts.index], y=\"Close\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testLevelStationarity(ts):\n",
    "    d = ndiffs(ts, test='kpss')\n",
    "    d += ndiffs(ts, test='adf')\n",
    "    d += ndiffs(ts, test='pp')\n",
    "    \n",
    "    return int(d/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_tests(data):\n",
    "     \n",
    "    result1 = pm.arima.nsdiffs(data, m=12, max_D=12, test='ch')\n",
    "    \n",
    "    print(\"CH results: \" + str(result1))\n",
    "    \n",
    "    result2 = pm.arima.nsdiffs(data, m=12, max_D=12, test='ocsb')\n",
    "    \n",
    "    print(\"OCSB results: \" + str(result2))\n",
    "    \n",
    "    return int((result1+result2)/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_tests(ts.Close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lag Period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.DataFrame (diff,columns=['Difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lag_period(data):\n",
    "    \n",
    "    fig = px.line(ts.Close, x=[ts.index], y=\"Close\")\n",
    "    fig.add_vline(x='2010-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x='2011-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x='2012-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x='2013-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x='2014-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x='2015-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x='2016-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x='2017-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.add_vline(x='2018-01-01', line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    fig.show()\n",
    "    \n",
    "    adf_test = ADFTest(alpha = 0.05)\n",
    "    \n",
    "    test = list()\n",
    "    lags = [365, 182, 90, 30, 14]\n",
    "    \n",
    "    # original data\n",
    "    test.append(adf_test.should_diff(data))\n",
    "    print(test[0])\n",
    "    \n",
    "    # year lag\n",
    "    test.append(adf_test.should_diff(difference(data, 365)))\n",
    "    print(test[1])\n",
    "    \n",
    "    # six months lag\n",
    "    test.append(adf_test.should_diff(difference(data, 182))) \n",
    "    print(test[2])\n",
    "    \n",
    "    # three months lag \n",
    "    test.append(adf_test.should_diff(difference(data, 90)))\n",
    "    print(test[3])\n",
    "    \n",
    "    # one month lag \n",
    "    test.append(adf_test.should_diff(difference(data, 30)))\n",
    "    print(test[4])\n",
    "    \n",
    "    # fortnight lag\n",
    "    test.append(adf_test.should_diff(difference(data, 14))) \n",
    "    print(test[5])\n",
    "    \n",
    "    # finds the first lag that doesn't need to be differenced\n",
    "    for i in range(6):\n",
    "        if (test[i][1] == False):\n",
    "            return int(lags[i])\n",
    "        \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(find_lag_period(ts.Close))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AR & MA Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAicBicHqic(dataset, arimaOrder, seasonalOrder):\n",
    "    \n",
    "    try:\n",
    "        model = sm.tsa.statespace.SARIMAX(dataset, order = arimaOrder, seasonal_order=seasonalOrder).fit(disp=False)\n",
    "\n",
    "        aic = model.aic\n",
    "        bic = model.bic\n",
    "        hqic = model.hqic\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return aic, bic, hqic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluateSarimaModels(dataset, pVals, dVal, qVals, seasonalPVals, seasonalDval, seasonalQVals, m):\n",
    "    \n",
    "    model = sm.tsa.statespace.SARIMAX(dataset, order = (0,0,0), seasonal_order=(0,0,0,m)).fit(disp=False)\n",
    "\n",
    "    bestAic = model.aic\n",
    "    bestBic = model.bic\n",
    "    bestHqic = model.hqic\n",
    "    \n",
    "    for p in pVals:\n",
    "        for q in qVals:\n",
    "            for seasonalP in seasonalPVals:\n",
    "                for seasonalQ in seasonalQVals:\n",
    "                    order=(p,dVal,q)\n",
    "                    seasonalOrder = (seasonalP, seasonalDval, seasonalQ, m)\n",
    "                    try:\n",
    "                        aic, bic, hqic = getAicBicHqic(dataset, order, seasonalOrder)\n",
    "                        if(((aic < bestAic) and (bic<bestBic)) or ((aic < bestAic) and (hqic<bestHqic)) or ((bic<bestBic) and (hqic<bestHqic))):\n",
    "                            bestAic = aic\n",
    "                            bestBic = bic\n",
    "                            bestHqic = hqic\n",
    "                            bestOrder = order\n",
    "                            bestSeasonalOrder = seasonalOrder\n",
    "                        \n",
    "                    except:\n",
    "                        continue\n",
    "        print(bestOrder, bestSeasonalOrder, bestAic, bestBic, bestHqic)\n",
    "        return bestOrder, bestSeasonalOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "order, seasonalOrder = evaluateSarimaModels(ts.Close, [0,1], 1, [0,1], [0,1], 1, [0,1], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_model (data):\n",
    "#train_test_split\n",
    "    level_diff = testLevelStationarity(ts.Close)\n",
    "    \n",
    "    stepwise_model_7 = auto_arima(data, start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=12,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=level_diff, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "    \n",
    "    return stepwise_model_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_7 = sarima_model(ts.Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_stepwise_model_7 = auto_arima(normalised_Data, start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=12,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ts.Close.loc['2010-01-01':'2018-01-01']\n",
    "test_7 = ts.Close.loc['2017-12-20': '2018-01-01']\n",
    "test_31 = ts.Close.loc['2017-11-15':'2018-01-01']\n",
    "two_month = ts.Close.loc['2017-10-15':'2018-01-01']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (normali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.line(future_forecast_7, x=test_31.index, y=future_forecast_7)\n",
    "fig.add_scatter(x=test_31.index, y=test_31.values, mode='lines')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sm.tsa.statespace.SARIMAX(normalised_Data, order = (1,1,1), seasonal_order=(1,1,1,12)).fit(disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred = test.get_prediction(0,len(normalised_Data),dynamic=False,full_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred.conf_int(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_future_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reverse\n",
    "#restored_Data = (normalised_future_forecast*fitted_lambda +1)**(1/fitted_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(normalised_future_forecast, x=test_31.index, y=normalised_future_forecast)\n",
    "fig.add_scatter(x=test_31.index, y=test_31.values, mode='lines')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation of model fit\n",
    "#boxljung test\n",
    "#model_df is p+q\n",
    "#m is seasonal period\n",
    "#change boxpierce to true if you want to also run that test\n",
    "#lbVal is the Ljung-Box test statistic and pVal is its p value\n",
    "def getBoxLjung(data, lags, model_df, m):\n",
    "    #demean the data\n",
    "    demeanedData = data.sub(data.mean())\n",
    "    lbVal, pVal = statsmodels.stats.diagnostic.acorr_ljungbox(demeanedData, lags, boxpierce = False, model_df = model_df, period = m)\n",
    "    \n",
    "    return lbVal, pVal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass a fitted model\n",
    "#returns \n",
    "#JBVal = Jarque-Bera test statistic\n",
    "#JBPVal = pvalue of the test statistic\n",
    "def getJarqueBera(data):\n",
    "    \n",
    "    JBVal, JBPVal, skewness, kurtosis = statsmodels.stats.stattools.jarque_bera(data.resid)\n",
    "    \n",
    "    return JBVal, JBPVal, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to sort different models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "#input is a dataframe full of models\n",
    "#I assume that there is no column that represents the skewness of model\n",
    "def sort_models(models):\n",
    "    skewness = []\n",
    "    #loop to get summary table of every model, then get skewness\n",
    "    \n",
    "    #To iterate through the df and isolate the model\n",
    "    for index,rows in models.iterrows():\n",
    "        #wrong parameters, \n",
    "        summary_table = SARIMAXResults.summary(row['model'])\n",
    "        table_csv = summary_table.as_csv();\n",
    "\n",
    "        with open(table_csv, newline='') as myFile:\n",
    "            #reader object stores all data\n",
    "            reader = csv.reader(myFile)\n",
    "            #change to finds out what cell skewness is in\n",
    "            skewness.append(reader[2][3])\n",
    "    #at this point, skewness array should be full\n",
    "    models['skewness'] = skewness\n",
    "    return models;\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
